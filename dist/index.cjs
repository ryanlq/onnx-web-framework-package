'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

/**
 * æ¨¡å‹ç¼“å­˜ç®¡ç†å™¨
 * ä½¿ç”¨IndexedDBç¼“å­˜æ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒHTTP Rangeè¯·æ±‚
 */

class ModelCache {
  constructor() {
    this.dbName = 'ONNXModelCache';
    this.dbVersion = 1;
    this.storeName = 'models';
    this.db = null;
  }

  /**
   * åˆå§‹åŒ–ç¼“å­˜æ•°æ®åº“
   */
  async init() {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, this.dbVersion);

      request.onerror = () => reject(request.error);
      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };

      request.onupgradeneeded = (event) => {
        const db = event.target.result;
        if (!db.objectStoreNames.contains(this.storeName)) {
          const store = db.createObjectStore(this.storeName, { keyPath: 'url' });
          store.createIndex('timestamp', 'timestamp', { unique: false });
          store.createIndex('etag', 'etag', { unique: false });
        }
      };
    });
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜
   */
  async isCached(url) {
    if (!this.db) await this.init();

    return new Promise((resolve) => {
      const transaction = this.db.transaction([this.storeName], 'readonly');
      const store = transaction.objectStore(this.storeName);
      const request = store.get(url);

      request.onsuccess = () => {
        const cached = request.result;
        if (!cached) {
          resolve(null);
          return;
        }

        // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ24å°æ—¶ï¼‰
        const maxAge = 24 * 60 * 60 * 1000; // 24å°æ—¶
        if (Date.now() - cached.timestamp > maxAge) {
          this.removeFromCache(url);
          resolve(null);
          return;
        }

        resolve(cached);
      };

      request.onerror = () => resolve(null);
    });
  }

  /**
   * è·å–æ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒHTTP Rangeè¯·æ±‚
   */
  async getModel(url) {
    try {
      // é¦–å…ˆæ£€æŸ¥ç¼“å­˜
      const cached = await this.isCached(url);
      if (cached) {
        console.log(`ğŸ“¦ Loading model from cache: ${url}`);
        return cached.data;
      }

      console.log(`â¬‡ï¸  Fetching model from network: ${url}`);

      // æ£€æŸ¥æ˜¯å¦æ”¯æŒRangeè¯·æ±‚
      const headResponse = await fetch(url, { method: 'HEAD' });
      const supportsRange = headResponse.headers.get('Accept-Ranges') === 'bytes';
      const contentLength = headResponse.headers.get('Content-Length');
      const etag = headResponse.headers.get('ETag');

      let modelArray;

      if (supportsRange && contentLength && parseInt(contentLength) > 10 * 1024 * 1024) {
        // å¤§æ–‡ä»¶ä½¿ç”¨åˆ†å—ä¸‹è½½
        modelArray = await this.downloadInChunks(url, contentLength);
      } else {
        // å°æ–‡ä»¶ç›´æ¥ä¸‹è½½
        const response = await fetch(url);
        if (!response.ok) {
          throw new Error(`Failed to fetch model: ${response.statusText}`);
        }
        modelArray = await response.arrayBuffer();
      }

      // ç¼“å­˜æ¨¡å‹
      await this.cacheModel(url, modelArray, etag);

      return modelArray;
    } catch (error) {
      console.error(`Failed to get model ${url}:`, error);
      throw error;
    }
  }

  /**
   * åˆ†å—ä¸‹è½½å¤§æ–‡ä»¶
   */
  async downloadInChunks(url, contentLength) {
    const chunkSize = 1024 * 1024; // 1MB chunks
    const chunks = [];
    let downloaded = 0;

    console.log(`ğŸ“¥ Downloading large model in chunks (${Math.ceil(contentLength / chunkSize)} chunks)`);

    for (let start = 0; start < contentLength; start += chunkSize) {
      const end = Math.min(start + chunkSize - 1, contentLength - 1);
      const range = `bytes=${start}-${end}`;

      const response = await fetch(url, {
        headers: { Range: range }
      });

      if (!response.ok) {
        throw new Error(`Failed to download chunk ${range}: ${response.statusText}`);
      }

      const chunk = await response.arrayBuffer();
      chunks.push(chunk);
      downloaded += chunk.byteLength;

      // æ›´æ–°è¿›åº¦
      const progress = (downloaded / contentLength * 100).toFixed(1);
      console.log(`â³ Download progress: ${progress}% (${downloaded}/${contentLength} bytes)`);
    }

    // åˆå¹¶æ‰€æœ‰å—
    const totalSize = chunks.reduce((sum, chunk) => sum + chunk.byteLength, 0);
    const modelArray = new Uint8Array(totalSize);
    let offset = 0;

    for (const chunk of chunks) {
      modelArray.set(new Uint8Array(chunk), offset);
      offset += chunk.byteLength;
    }

    return modelArray;
  }

  /**
   * ç¼“å­˜æ¨¡å‹æ–‡ä»¶
   */
  async cacheModel(url, data, etag = null) {
    if (!this.db) await this.init();

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);

      const modelRecord = {
        url,
        data,
        timestamp: Date.now(),
        etag,
        size: data.byteLength || data.length
      };

      const request = store.put(modelRecord);
      request.onsuccess = () => resolve();
      request.onerror = () => reject(request.error);
    });
  }

  /**
   * ä»ç¼“å­˜ä¸­ç§»é™¤æ¨¡å‹
   */
  async removeFromCache(url) {
    if (!this.db) await this.init();

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);
      const request = store.delete(url);

      request.onsuccess = () => resolve();
      request.onerror = () => reject(request.error);
    });
  }

  /**
   * æ¸…ç†è¿‡æœŸç¼“å­˜
   */
  async cleanup() {
    if (!this.db) await this.init();

    const maxAge = 24 * 60 * 60 * 1000; // 24å°æ—¶
    const cutoffTime = Date.now() - maxAge;

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);
      const index = store.index('timestamp');
      const request = index.openCursor(IDBKeyRange.upperBound(cutoffTime));

      request.onsuccess = (event) => {
        const cursor = event.target.result;
        if (cursor) {
          cursor.delete();
          cursor.continue();
        } else {
          resolve();
        }
      };

      request.onerror = () => reject(request.error);
    });
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
   */
  async getStats() {
    if (!this.db) await this.init();

    return new Promise((resolve) => {
      const transaction = this.db.transaction([this.storeName], 'readonly');
      const store = transaction.objectStore(this.storeName);
      const request = store.getAll();

      request.onsuccess = () => {
        const models = request.result;
        const totalSize = models.reduce((sum, model) => sum + (model.size || 0), 0);
        const stats = {
          count: models.length,
          totalSize,
          models: models.map(model => ({
            url: model.url,
            size: model.size,
            timestamp: model.timestamp,
            age: Date.now() - model.timestamp
          }))
        };
        resolve(stats);
      };

      request.onerror = () => resolve({ count: 0, totalSize: 0, models: [] });
    });
  }
}

/**
 * ONNX Web Framework
 * åŸºäºONNX Runtime Webæ„å»ºï¼Œæ”¯æŒæ¨¡å‹ç¼“å­˜
 */


// ç¡®ä¿ortåœ¨å…¨å±€å¯ç”¨
// æµè§ˆå™¨ç¯å¢ƒï¼šé€šè¿‡ <script> æ ‡ç­¾åŠ è½½ UMD ç‰ˆæœ¬
// Node.jsç¯å¢ƒï¼šé€šè¿‡ npm install onnxruntime-web å®‰è£…ï¼ˆéœ€è¦æ„å»ºå·¥å…·å¤„ç†ï¼‰
let ort = null;

// æ£€æŸ¥å…¨å±€ ortï¼ˆé€šè¿‡ script æ ‡ç­¾åŠ è½½çš„ UMD ç‰ˆæœ¬ï¼‰
if (typeof globalThis !== 'undefined' && globalThis.ort && globalThis.ort.InferenceSession) {
  ort = globalThis.ort;
  console.log('âœ… ä½¿ç”¨å…¨å±€ ort (UMD ç‰ˆæœ¬)');
} else {
  // å¦‚æœæ²¡æœ‰å…¨å±€ ortï¼Œå°è¯•ä½¿ç”¨å·²å¯¼å…¥çš„æ¨¡å—ï¼ˆæ„å»ºæ—¶ä¼šå¤„ç†ï¼‰
  // æ³¨æ„ï¼šè¿™è¦æ±‚ onnxruntime-web åœ¨æ„å»ºæ—¶è¢«æ­£ç¡®æ‰“åŒ…æˆ–æ ‡è®°ä¸º external
  try {
    // è®¿é—®å¤–éƒ¨ä¾èµ–ï¼ˆç”±æ„å»ºå·¥å…·å¤„ç†ï¼‰
    ort = globalThis.ort;
    if (!ort) {
      throw new Error('ort not available');
    }
  } catch (error) {
    throw new Error(
      'ONNX Runtime Web æœªæ­£ç¡®åŠ è½½ã€‚\n\n' +
      'æµè§ˆå™¨ç¯å¢ƒï¼šè¯·åœ¨ HTML ä¸­æ·»åŠ :\n' +
      '  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/ort.min.js"></script>\n\n' +
      'Node.jsç¯å¢ƒï¼šè¯·è¿è¡Œ:\n' +
      '  npm install onnxruntime-web'
    );
  }
}

class ONNXWebFramework {
  constructor(options = {}) {
    this.options = {
      // ç¼“å­˜é…ç½®
      enableCache: options.enableCache !== false, // é»˜è®¤å¯ç”¨ç¼“å­˜
      cacheMaxAge: options.cacheMaxAge || 24 * 60 * 60 * 1000, // 24å°æ—¶

      // ORTé…ç½®
      executionProviders: options.executionProviders || ['wasm'],
      enableProfiling: options.enableProfiling || false,
      debug: options.debug || false,
      logLevel: options.logLevel || 'warning',
      numThreads: options.numThreads || 0,

      // WASMè·¯å¾„é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤è®©æ‰“åŒ…å·¥å…·è‡ªåŠ¨å¤„ç†ï¼‰
      // åªæœ‰åœ¨éœ€è¦è‡ªå®šä¹‰è·¯å¾„æ—¶æ‰è®¾ç½®ä¸ºå­—ç¬¦ä¸²
      wasmPaths: options.wasmPaths || null,

      // é¢„å¤„ç†å’Œåå¤„ç†é’©å­
      preprocessors: options.preprocessors || {}, // { modelName: (rawInput) => tensor }
      postprocessors: options.postprocessors || {}, // { modelName: (output) => processedOutput }

      ...options
    };

    // ç¼“å­˜å’Œæ¨¡å‹
    this.modelCache = new ModelCache();
    this.models = new Map();
    this.isInitialized = false;

    // é¢„å¤„ç†å’Œåå¤„ç†å™¨æ³¨å†Œè¡¨
    this.preprocessors = new Map(); // modelName -> function
    this.postprocessors = new Map(); // modelName -> function

    // åˆå§‹åŒ–é¢„é…ç½®çš„å¤„ç†å™¨
    for (const [modelName, processor] of Object.entries(this.options.preprocessors)) {
      this.preprocessors.set(modelName, processor);
    }
    for (const [modelName, processor] of Object.entries(this.options.postprocessors)) {
      this.postprocessors.set(modelName, processor);
    }
  }

  /**
   * åˆå§‹åŒ–æ¡†æ¶
   */
  async initialize() {
    try {
      console.log('ğŸš€ Initializing ONNX Web Framework...');

      // ä¸è®¾ç½® wasmPathsï¼Œè®©æ‰“åŒ…å·¥å…·è‡ªåŠ¨å¤„ç†
      // å¦‚éœ€è‡ªå®šä¹‰è·¯å¾„ï¼Œå¯é€šè¿‡ options.wasmPaths ä¼ å…¥
      if (this.options.wasmPaths && typeof this.options.wasmPaths === 'string') {
        ort.env.wasm.wasmPaths = this.options.wasmPaths;
        console.log(`ğŸ“ Using custom WASM paths: ${this.options.wasmPaths}`);
      } else {
        console.log('ğŸ“ Using default WASM loader (bundle tool will handle it)');
      }

      // åˆå§‹åŒ–ç¼“å­˜
      if (this.options.enableCache) {
        await this.modelCache.init();
        await this.modelCache.cleanup();
        console.log('âœ… Model cache initialized');
      }

      this.isInitialized = true;
      console.log('âœ… ONNX Web Framework initialized successfully');

      // æ‰“å°ç¼“å­˜ç»Ÿè®¡
      if (this.options.enableCache) {
        const stats = await this.modelCache.getStats();
        console.log(`ğŸ“Š Cache stats: ${stats.count} models, ${(stats.totalSize / 1024 / 1024).toFixed(2)}MB`);
      }

    } catch (error) {
      console.error('âŒ Failed to initialize framework:', error);
      throw error;
    }
  }


  /**
   * åŠ è½½æ¨¡å‹
   */
  async loadModel(name, modelSource, sessionOptions = {}) {
    if (!this.isInitialized) {
      throw new Error('Framework not initialized. Call initialize() first.');
    }

    console.log(`ğŸ“¦ Loading model '${name}'...`);

    try {
      // è·å–æ¨¡å‹æ•°æ®
      let modelArray;
      let modelFormat = 'unknown';

      if (typeof modelSource === 'string') {
        // ä¼˜å…ˆå°è¯•ORTæ ¼å¼
        const ortSource = modelSource.replace(/\.onnx$/, '.ort');

        try {
          modelArray = await this.modelCache.getModel(ortSource);
          modelFormat = 'ort';
          console.log(`âœ… Using ORT format model: ${ortSource}`);
        } catch (ortError) {
          // å›é€€åˆ°ONNXæ ¼å¼
          console.log(`âš ï¸  ORT format not available, using ONNX format`);
          modelArray = await this.modelCache.getModel(modelSource);
          modelFormat = 'onnx';
        }
      } else if (modelSource instanceof Uint8Array || modelSource instanceof ArrayBuffer) {
        modelArray = modelSource;
        modelFormat = 'array';
      } else {
        throw new Error('Invalid model source. Must be URL, Uint8Array, or ArrayBuffer.');
      }

      // åœ¨ä¸»çº¿ç¨‹åŠ è½½æ¨¡å‹
      console.log('âš ï¸  Loading model in main thread (UI may be blocked during inference)');
      const finalOptions = {
        executionProviders: sessionOptions.executionProviders || this.options.executionProviders,
        enableProfiling: sessionOptions.enableProfiling || this.options.enableProfiling,
        ...sessionOptions
      };

      const session = await ort.InferenceSession.create(modelArray, finalOptions);

      // ä¿å­˜æ¨¡å‹ä¿¡æ¯
      this.models.set(name, {
        session,
        modelFormat,
        modelPath: modelSource,
        inputNames: session.inputNames,
        outputNames: session.outputNames
      });

      console.log(`âœ… Model '${name}' loaded successfully (${modelFormat})`);
      return {
        modelName: name,
        loaded: true,
        inputNames: session.inputNames,
        outputNames: session.outputNames
      };

    } catch (error) {
      console.error(`âŒ Failed to load model '${name}':`, error);
      throw error;
    }
  }

  /**
   * æ‰§è¡Œæ¨ç†
   */
  async run(modelName, feeds) {
    if (!this.isInitialized) {
      throw new Error('Framework not initialized. Call initialize() first.');
    }

    const model = this.models.get(modelName);
    if (!model) {
      throw new Error(`Model '${modelName}' not loaded`);
    }

    try {
      // åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œæ¨ç†
      const result = await model.session.run(feeds);
      return result;

    } catch (error) {
      console.error(`âŒ Failed to run inference with model '${modelName}':`, error);
      throw error;
    }
  }

  /**
   * æ‰§è¡Œæ¨ç†ï¼ˆå¸¦é¢„å¤„ç†å’Œåå¤„ç†ï¼‰
   * è¿™æ˜¯ä¸€ä¸ªé«˜çº§ APIï¼Œä¼šè‡ªåŠ¨è°ƒç”¨æ³¨å†Œçš„é¢„å¤„ç†å™¨å’Œåå¤„ç†å™¨
   *
   * @param {string} modelName - æ¨¡å‹åç§°
   * @param {*} rawInput - åŸå§‹è¾“å…¥ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒç­‰ï¼‰
   * @param {object} options - é€‰é¡¹
   * @returns {Promise<*>} å¤„ç†åçš„è¾“å‡º
   */
  async predict(modelName, rawInput, options = {}) {
    if (!this.isInitialized) {
      throw new Error('Framework not initialized. Call initialize() first.');
    }

    const model = this.models.get(modelName);
    if (!model) {
      throw new Error(`Model '${modelName}' not loaded`);
    }

    try {
      console.log(`ğŸ”® Running prediction with model '${modelName}'...`);

      // 1. é¢„å¤„ç†
      let feeds;
      const preprocessor = this.preprocessors.get(modelName);

      if (preprocessor) {
        console.log('âš™ï¸  Running preprocessor...');
        feeds = await preprocessor(rawInput, options);
      } else {
        console.warn(`âš ï¸  No preprocessor registered for '${modelName}', assuming input is preprocessed`);
        // å‡è®¾è¾“å…¥å·²ç»æ˜¯å¤„ç†å¥½çš„ tensor æ ¼å¼
        feeds = rawInput;
      }

      // 2. è¿è¡Œæ¨ç†
      const results = await this.run(modelName, feeds);

      // 3. åå¤„ç†
      const postprocessor = this.postprocessors.get(modelName);
      let processedResults;

      if (postprocessor) {
        console.log('âš™ï¸  Running postprocessor...');
        processedResults = await postprocessor(results, options);
      } else {
        console.warn(`âš ï¸  No postprocessor registered for '${modelName}', returning raw output`);
        processedResults = results;
      }

      console.log('âœ… Prediction completed');
      return processedResults;

    } catch (error) {
      console.error(`âŒ Prediction failed for model '${modelName}':`, error);
      throw error;
    }
  }

  /**
   * é¢„å¤„ç†è¾“å…¥æ•°æ®
   */
  async preprocessInput(model, rawData, preprocessOptions) {
    const processed = {};

    for (const [inputName, inputMeta] of Object.entries(model.inputMetadata)) {
      let inputTensor;

      if (rawData instanceof HTMLImageElement || rawData instanceof HTMLCanvasElement) {
        // å›¾åƒé¢„å¤„ç†
        inputTensor = await this.preprocessImage(rawData, inputMeta, preprocessOptions);
      } else if (Array.isArray(rawData) || rawData instanceof Float32Array) {
        // æ•°ç»„æ•°æ®
        inputTensor = {
          data: rawData,
          shape: preprocessOptions.resize || inputMeta.shape || [1, rawData.length]
        };
      } else if (typeof rawData === 'object' && rawData[inputName]) {
        // å·²ç»æ˜¯å¤„ç†è¿‡çš„å¯¹è±¡
        inputTensor = rawData[inputName];
      } else {
        throw new Error(`Unsupported input data type for '${inputName}'`);
      }

      processed[inputName] = inputTensor;
    }

    return processed;
  }

  /**
   * å›¾åƒé¢„å¤„ç†
   */
  async preprocessImage(image, inputMeta, options) {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');

    // è°ƒæ•´å°ºå¯¸
    const targetSize = options.resize || [224, 224];
    canvas.width = targetSize[1];
    canvas.height = targetSize[0];

    // ç»˜åˆ¶å›¾åƒ
    ctx.drawImage(image, 0, 0, canvas.width, canvas.height);

    // è·å–åƒç´ æ•°æ®
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const pixels = imageData.data;

    // è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„æ ¼å¼
    const isRGB = options.colorFormat === 'rgb';
    options.normalization || 'zeroToOne';
    const channels = isRGB ? 3 : 4; // RGBæˆ–RGBA
    const data = new Float32Array(canvas.width * canvas.height * channels);

    for (let i = 0, j = 0; i < pixels.length; i += 4, j += channels) {
      // RGBé€šé“
      if (isRGB) {
        data[j] = pixels[i] / 255;     // R
        data[j + 1] = pixels[i + 1] / 255; // G
        data[j + 2] = pixels[i + 2] / 255; // B
      } else {
        data[j] = pixels[i] / 255;     // R
        data[j + 1] = pixels[i + 1] / 255; // G
        data[j + 2] = pixels[i + 2] / 255; // B
        data[j + 3] = pixels[i + 3] / 255; // A
      }
    }

    return {
      data,
      shape: [1, channels, canvas.height, canvas.width] // NCHWæ ¼å¼
    };
  }

  /**
   * è·å–æ¨¡å‹ä¿¡æ¯
   */
  getModelInfo(modelName) {
    return this.models.get(modelName);
  }

  /**
   * åˆ—å‡ºå·²åŠ è½½çš„æ¨¡å‹
   */
  listModels() {
    return Array.from(this.models.keys());
  }

  /**
   * å¸è½½æ¨¡å‹
   */
  async unloadModel(modelName) {
    const model = this.models.get(modelName);
    if (model && model.session) {
      await model.session.release();
    }
    this.models.delete(modelName);
    console.log(`ğŸ—‘ï¸  Model '${modelName}' unloaded`);
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡
   */
  async getCacheStats() {
    if (!this.options.enableCache) {
      return { enabled: false };
    }

    return await this.modelCache.getStats();
  }

  /**
   * æ¸…ç†ç¼“å­˜
   */
  async clearCache() {
    if (!this.options.enableCache) {
      return;
    }

    await this.modelCache.cleanup();
    console.log('ğŸ§¹ Cache cleared');
  }

  /**
   * æ³¨å†Œé¢„å¤„ç†å™¨
   * @param {string} modelName - æ¨¡å‹åç§°
   * @param {function} processor - é¢„å¤„ç†å‡½æ•° (rawInput) => feeds
   */
  registerPreprocessor(modelName, processor) {
    this.preprocessors.set(modelName, processor);
    console.log(`âœ… Preprocessor registered for '${modelName}'`);
  }

  /**
   * æ³¨å†Œåå¤„ç†å™¨
   * @param {string} modelName - æ¨¡å‹åç§°
   * @param {function} processor - åå¤„ç†å‡½æ•° (output) => processedOutput
   */
  registerPostprocessor(modelName, processor) {
    this.postprocessors.set(modelName, processor);
    console.log(`âœ… Postprocessor registered for '${modelName}'`);
  }

  /**
   * å–æ¶ˆæ³¨å†Œé¢„å¤„ç†å™¨
   * @param {string} modelName - æ¨¡å‹åç§°
   */
  unregisterPreprocessor(modelName) {
    this.preprocessors.delete(modelName);
    console.log(`ğŸ—‘ï¸  Preprocessor unregistered for '${modelName}'`);
  }

  /**
   * å–æ¶ˆæ³¨å†Œåå¤„ç†å™¨
   * @param {string} modelName - æ¨¡å‹åç§°
   */
  unregisterPostprocessor(modelName) {
    this.postprocessors.delete(modelName);
    console.log(`ğŸ—‘ï¸  Postprocessor unregistered for '${modelName}'`);
  }

  /**
   * æ¸…ç†æ‰€æœ‰èµ„æº
   */
  async dispose() {
    // æ¸…ç†Worker
    if (this.workerManager) {
      await this.workerManager.dispose();
      this.workerManager = null;
    }

    // æ¸…ç†æ¨¡å‹
    this.models.clear();

    console.log('ğŸ§¹ ONNX Web Framework disposed');
  }
}

/**
 * ONNX Web Worker ç±»å‹å®šä¹‰
 *
 * å®šä¹‰ Worker å’Œä¸»çº¿ç¨‹ä¹‹é—´çš„æ¶ˆæ¯åè®®
 */

/**
 * Worker æ¶ˆæ¯ç±»å‹æšä¸¾
 */
const WorkerMessageType = {
  INITIALIZE: "initialize",
  LOAD_MODEL: "load_model",
  RUN_INFERENCE: "run_inference",
  DISPOSE: "dispose",
  RESULT: "result",
  ERROR: "error",
};

/**
 * åˆå§‹åŒ–é…ç½®
 */
class InitializeConfig {
  constructor(options = {}) {
    /**
     * WASM æ–‡ä»¶è·¯å¾„é…ç½®
     * @type {string | Record<string, string>}
     */
    this.wasmPaths = options.wasmPaths || null;

    /**
     * çº¿ç¨‹æ•°é‡ï¼ˆ0 = ä½¿ç”¨é»˜è®¤å€¼ï¼‰
     * @type {number}
     */
    this.numThreads = options.numThreads || 0;

    /**
     * æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æ
     * @type {boolean}
     */
    this.enableProfiling = options.enableProfiling || false;

    /**
     * æ‰§è¡Œæä¾›è€…åˆ—è¡¨
     * @type {string[]}
     */
    this.executionProviders = options.executionProviders || ["wasm"];
  }
}

/**
 * å¼ é‡æ•°æ®
 */
class TensorData {
  constructor(data, dims, type = "float32") {
    /**
     * å¼ é‡æ•°æ®ï¼ˆFloat32Array | Int32Array | Uint8Array | BigInt64Arrayï¼‰
     */
    this.data = data;

    /**
     * å¼ é‡ç»´åº¦
     * @type {number[]}
     */
    this.dims = dims;

    /**
     * æ•°æ®ç±»å‹
     * @type {'float32' | 'int32' | 'uint8' | 'int64'}
     */
    this.type = type;
  }
}

/**
 * åŠ è½½æ¨¡å‹è¯·æ±‚
 */
class LoadModelRequest {
  constructor(id, modelName, modelBuffer, sessionOptions = {}) {
    /**
     * è¯·æ±‚ ID
     * @type {string}
     */
    this.id = id;

    /**
     * è¯·æ±‚ç±»å‹
     * @type {string}
     */
    this.type = WorkerMessageType.LOAD_MODEL;

    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * æ¨¡å‹æ•°æ®ï¼ˆArrayBufferï¼‰
     * @type {ArrayBuffer}
     */
    this.modelBuffer = modelBuffer;

    /**
     * Session é…ç½®é€‰é¡¹
     * @type {Object}
     */
    this.sessionOptions = sessionOptions;
  }
}

/**
 * æ¨ç†è¯·æ±‚
 */
class RunInferenceRequest {
  constructor(id, modelName, inputs) {
    /**
     * è¯·æ±‚ ID
     * @type {string}
     */
    this.id = id;

    /**
     * è¯·æ±‚ç±»å‹
     * @type {string}
     */
    this.type = WorkerMessageType.RUN_INFERENCE;

    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * è¾“å…¥å¼ é‡å­—å…¸
     * @type {Record<string, TensorData>}
     */
    this.inputs = inputs;
  }
}

/**
 * Worker å“åº”
 */
class WorkerResponse {
  constructor(id, type, data = null, error = null) {
    /**
     * å“åº” IDï¼ˆå¯¹åº”è¯·æ±‚ IDï¼‰
     * @type {string}
     */
    this.id = id;

    /**
     * å“åº”ç±»å‹
     * @type {string}
     */
    this.type = type;

    /**
     * å“åº”æ•°æ®
     * @type {any}
     */
    this.data = data;

    /**
     * é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
     * @type {string | null}
     */
    this.error = error;
  }
}

/**
 * æ¨¡å‹ä¿¡æ¯
 */
class ModelInfo {
  constructor(modelName, inputNames, outputNames) {
    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * è¾“å…¥åç§°åˆ—è¡¨
     * @type {string[]}
     */
    this.inputNames = inputNames;

    /**
     * è¾“å‡ºåç§°åˆ—è¡¨
     * @type {string[]}
     */
    this.outputNames = outputNames;
  }
}

/**
 * ONNX Worker Proxy
 *
 * å°è£… Worker é€šä¿¡ï¼Œæä¾› Promise API
 * ä½¿ç”¨ Proxy æ¨¡å¼è®©è°ƒç”¨ Worker å°±åƒè°ƒç”¨æœ¬åœ°å‡½æ•°ä¸€æ ·ç®€å•
 *
 * ä½¿ç”¨ç¤ºä¾‹:
 * ```javascript
 * import workerUrl from 'onnx-web-framework/worker?worker&url'
 * import { createOnnxWorkerProxy } from 'onnx-web-framework'
 *
 * const worker = new Worker(workerUrl, { type: 'module' })
 * const proxy = createOnnxWorkerProxy(worker)
 *
 * await proxy.initialize({ wasmPaths: '/wasm/' })
 * await proxy.loadModel('model', modelBuffer)
 * const result = await proxy.run('model', inputs)
 * ```
 */


/**
 * ONNX Worker ä»£ç†ç±»
 *
 * å°è£… Worker é€šä¿¡ï¼Œæä¾› Promise API
 */
class ONNXWorkerProxy {
  /**
   * æ„é€ å‡½æ•°
   *
   * @param {Worker} worker - Web Worker å®ä¾‹
   */
  constructor(worker) {
    /**
     * Web Worker å®ä¾‹
     * @type {Worker}
     * @private
     */
    this.worker = worker;

    /**
     * è¯·æ±‚ ID è®¡æ•°å™¨
     * @type {number}
     * @private
     */
    this.requestId = 0;

    /**
     * å¾…å¤„ç†çš„è¯·æ±‚ Map
     * @type {Map<number, {resolve: Function, reject: Function, timeout: number}>}
     * @private
     */
    this.pendingRequests = new Map();

    /**
     * é»˜è®¤è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
     * @type {number}
     * @private
     */
    this.defaultTimeout = 60000; // 60ç§’

    /**
     * æ˜¯å¦å·²é‡Šæ”¾
     * @type {boolean}
     * @private
     */
    this.isDisposed = false;

    // ç»‘å®šæ¶ˆæ¯å¤„ç†å™¨
    this.worker.onmessage = this._handleMessage.bind(this);

    // ç»‘å®šé”™è¯¯å¤„ç†å™¨
    this.worker.onerror = this._handleError.bind(this);
  }

  /**
   * å¤„ç† Worker æ¶ˆæ¯
   * @private
   *
   * @param {MessageEvent<WorkerResponse>} e - æ¶ˆæ¯äº‹ä»¶
   */
  _handleMessage(e) {
    if (this.isDisposed) return;

    const res = e.data;
    const pending = this.pendingRequests.get(res.id);

    if (!pending) {
      console.warn(`[WorkerProxy] æ²¡æœ‰æ‰¾åˆ° ID ä¸º ${res.id} çš„å¾…å¤„ç†è¯·æ±‚`);
      return;
    }

    // æ¸…ç†è¶…æ—¶å®šæ—¶å™¨
    if (pending.timeout) {
      clearTimeout(pending.timeout);
    }

    // ä»å¾…å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
    this.pendingRequests.delete(res.id);

    // å¤„ç†å“åº”
    if (res.type === WorkerMessageType.ERROR || res.error) {
      pending.reject(new Error(res.error || 'Unknown error'));
    } else {
      pending.resolve(res.data);
    }
  }

  /**
   * å¤„ç† Worker é”™è¯¯
   * @private
   *
   * @param {ErrorEvent} e - é”™è¯¯äº‹ä»¶
   */
  _handleError(e) {
    console.error('[WorkerProxy] Worker é”™è¯¯:', e.message, e);

    // æ‹’ç»æ‰€æœ‰å¾…å¤„ç†çš„è¯·æ±‚
    for (const [id, pending] of this.pendingRequests.entries()) {
      if (pending.timeout) {
        clearTimeout(pending.timeout);
      }
      pending.reject(new Error(`Worker error: ${e.message}`));
    }

    this.pendingRequests.clear();
  }

  /**
   * å‘é€è¯·æ±‚åˆ° Worker
   * @private
   *
   * @param {string} type - è¯·æ±‚ç±»å‹
   * @param {Object} data - è¯·æ±‚æ•°æ®
   * @param {number} timeout - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   * @returns {Promise<any>}
   */
  async _request(type, data = {}, timeout = null) {
    if (this.isDisposed) {
      throw new Error('WorkerProxy has been disposed');
    }

    const id = ++this.requestId;
    const reqTimeout = timeout || this.defaultTimeout;

    return new Promise((resolve, reject) => {
      // åˆ›å»ºè¶…æ—¶å®šæ—¶å™¨
      const timeoutId = setTimeout(() => {
        this.pendingRequests.delete(id);
        reject(new Error(`Request timeout: ${type} (${reqTimeout}ms)`));
      }, reqTimeout);

      // ä¿å­˜å¾…å¤„ç†è¯·æ±‚
      this.pendingRequests.set(id, {
        resolve,
        reject,
        timeout: timeoutId
      });

      // å‘é€æ¶ˆæ¯åˆ° Worker
      try {
        this.worker.postMessage({
          id,
          type,
          ...data
        });
      } catch (error) {
        // å‘é€å¤±è´¥ï¼Œç«‹å³æ¸…ç†
        clearTimeout(timeoutId);
        this.pendingRequests.delete(id);
        reject(error);
      }
    });
  }

  /**
   * åˆå§‹åŒ– Worker
   *
   * @param {Partial<InitializeConfig>} config - åˆå§‹åŒ–é…ç½®
   * @returns {Promise<void>}
   *
   * @example
   * await proxy.initialize({
   *   wasmPaths: 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/',
   *   numThreads: 4
   * })
   */
  async initialize(config = {}) {
    const initConfig = new InitializeConfig(config);
    await this._request(WorkerMessageType.INITIALIZE, { config: initConfig });
    console.log('[WorkerProxy] âœ… Worker åˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * åŠ è½½æ¨¡å‹
   *
   * @param {string} modelName - æ¨¡å‹åç§°ï¼ˆç”¨äºåç»­å¼•ç”¨ï¼‰
   * @param {ArrayBuffer} modelBuffer - æ¨¡å‹æ•°æ®ï¼ˆArrayBufferï¼‰
   * @param {Object} sessionOptions - Session é…ç½®é€‰é¡¹
   * @returns {Promise<{modelName: string, inputNames: string[], outputNames: string[]}>}
   *
   * @example
   * const modelResponse = await fetch('/models/model.onnx')
   * const modelBuffer = await modelResponse.arrayBuffer()
   * const info = await proxy.loadModel('my-model', modelBuffer)
   * console.log('è¾“å…¥:', info.inputNames)
   * console.log('è¾“å‡º:', info.outputNames)
   */
  async loadModel(modelName, modelBuffer, sessionOptions = {}) {
    if (!modelName) {
      throw new Error('modelName is required');
    }
    if (!modelBuffer) {
      throw new Error('modelBuffer is required');
    }

    const result = await this._request(WorkerMessageType.LOAD_MODEL, {
      modelName,
      modelBuffer,
      sessionOptions
    });

    console.log(`[WorkerProxy] âœ… æ¨¡å‹ '${modelName}' åŠ è½½æˆåŠŸ`);
    return result;
  }

  /**
   * è¿è¡Œæ¨ç†
   *
   * @param {string} modelName - æ¨¡å‹åç§°
   * @param {Record<string, TensorData>} inputs - è¾“å…¥å¼ é‡å­—å…¸
   * @returns {Promise<Record<string, TensorData>>} è¾“å‡ºå¼ é‡å­—å…¸
   *
   * @example
   * const result = await proxy.run('my-model', {
   *   input: {
   *     data: new Float32Array([1, 2, 3]),
   *     dims: [1, 3],
   *     type: 'float32'
   *   }
   * })
   */
  async run(modelName, inputs) {
    if (!modelName) {
      throw new Error('modelName is required');
    }
    if (!inputs || Object.keys(inputs).length === 0) {
      throw new Error('inputs is required');
    }

    return await this._request(WorkerMessageType.RUN_INFERENCE, {
      modelName,
      inputs
    });
  }

  /**
   * é‡Šæ”¾ Worker èµ„æº
   *
   * @returns {Promise<void>}
   *
   * @example
   * await proxy.dispose()
   */
  async dispose() {
    if (this.isDisposed) {
      console.warn('[WorkerProxy] å·²ç»é‡Šæ”¾è¿‡äº†');
      return;
    }

    console.log('[WorkerProxy] æ­£åœ¨é‡Šæ”¾...');

    // å‘é€é‡Šæ”¾æ¶ˆæ¯
    try {
      await this._request(WorkerMessageType.DISPOSE, {}, 5000);
    } catch (error) {
      console.warn('[WorkerProxy] é‡Šæ”¾æ¶ˆæ¯å‘é€å¤±è´¥:', error);
    }

    // æ¸…ç†æ‰€æœ‰å¾…å¤„ç†è¯·æ±‚
    for (const [id, pending] of this.pendingRequests.entries()) {
      if (pending.timeout) {
        clearTimeout(pending.timeout);
      }
      pending.reject(new Error('Worker disposed'));
    }

    this.pendingRequests.clear();

    // ç»ˆæ­¢ Worker
    this.worker.terminate();

    // æ ‡è®°ä¸ºå·²é‡Šæ”¾
    this.isDisposed = true;

    console.log('[WorkerProxy] âœ… é‡Šæ”¾å®Œæˆ');
  }

  /**
   * æ£€æŸ¥ Worker æ˜¯å¦å·²é‡Šæ”¾
   *
   * @returns {boolean}
   */
  get disposed() {
    return this.isDisposed;
  }
}

/**
 * åˆ›å»º ONNX Worker ä»£ç†
 *
 * è¿™æ˜¯æ¨èçš„åˆ›å»º Worker Proxy çš„æ–¹å¼
 *
 * @param {Worker} worker - Web Worker å®ä¾‹
 * @returns {ONNXWorkerProxy} Worker ä»£ç†å®ä¾‹
 *
 * @example
 * // Vite é¡¹ç›®
 * import workerUrl from 'onnx-web-framework/worker?worker&url'
 * import { createOnnxWorkerProxy } from 'onnx-web-framework'
 *
 * const worker = new Worker(workerUrl, { type: 'module' })
 * const proxy = createOnnxWorkerProxy(worker)
 *
 * await proxy.initialize()
 * await proxy.loadModel('model', modelBuffer)
 * const result = await proxy.run('model', inputs)
 */
function createOnnxWorkerProxy(worker) {
  return new ONNXWorkerProxy(worker);
}

/**
 * Tokenizer åŠ è½½å™¨å’Œå·¥å…·ç±»
 *
 * æ”¯æŒä» URL åŠ è½½ tokenizer é…ç½®ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„åˆ†è¯æ¥å£
 */

/**
 * Tokenizer åŸºç¡€æ¥å£
 * æ‰€æœ‰ tokenizer æ’ä»¶éƒ½éœ€è¦å®ç°è¿™ä¸ªæ¥å£
 */
class ITokenizer {
  /**
   * ç¼–ç ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸º tokens
   * @param {string} text - è¾“å…¥æ–‡æœ¬
   * @returns {{ids: number[], attentionMask: number[], typeIds: number[]}}
   */
  encode(text) {
    throw new Error('encode() must be implemented by subclass');
  }

  /**
   * è§£ç ï¼šå°† tokens è½¬æ¢å›æ–‡æœ¬
   * @param {number[]} ids - token IDs
   * @returns {string}
   */
  decode(ids) {
    throw new Error('decode() must be implemented by subclass');
  }

  /**
   * è·å–è¯æ±‡è¡¨å¤§å°
   * @returns {number}
   */
  get vocabSize() {
    throw new Error('vocabSize getter must be implemented by subclass');
  }
}

/**
 * JSON Tokenizerï¼ˆHuggingFace æ ¼å¼ï¼‰
 * æ”¯æŒä» tokenizer.json åŠ è½½
 */
class JSONTokenizer extends ITokenizer {
  constructor(config) {
    super();
    this.config = config;
    this.vocab = config.model?.vocab || {};
    this.merges = config.model?.merges || [];
    this.addedTokens = config.added_tokens || [];
    this._buildTrie();
  }

  /**
   * æ„å»º Trie æ ‘ç”¨äºå¿«é€ŸæŸ¥æ‰¾
   * @private
   */
  _buildTrie() {
    this.trie = {};
    for (const [token, id] of Object.entries(this.vocab)) {
      let node = this.trie;
      for (const char of token) {
        if (!node[char]) node[char] = {};
        node = node[char];
      }
      node._end = id;
    }
  }

  /**
   * ç¼–ç æ–‡æœ¬
   * @param {string} text
   * @returns {{ids: number[], attentionMask: number[], typeIds: number[]}}
   */
  encode(text) {
    // ç®€åŒ–çš„ BPE å®ç°ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ tokenizers.jsï¼‰
    const tokens = this._bpeEncode(text);
    const ids = tokens.map(t => this.vocab[t] || this.vocab['<unk>']);

    return {
      ids,
      attentionMask: ids.map(() => 1),
      typeIds: ids.map(() => 0)
    };
  }

  /**
   * BPE ç¼–ç ï¼ˆç®€åŒ–ç‰ˆï¼‰
   * @private
   */
  _bpeEncode(text) {
    // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°
    // å®é™…ä½¿ç”¨æ—¶å»ºè®®é›†æˆ tokenizers.js æˆ– @nlpjs/bpe
    const words = text.split(/\s+/);
    const tokens = [];

    for (const word of words) {
      // ç®€å•çš„å­—ç¬¦çº§åˆ†è¯ä½œä¸º fallback
      if (this.vocab[word] !== undefined) {
        tokens.push(word);
      } else {
        // æŒ‰å­—ç¬¦åˆ‡åˆ†
        for (const char of word) {
          if (this.vocab[char] !== undefined) {
            tokens.push(char);
          }
        }
      }
    }

    return tokens;
  }

  /**
   * è§£ç  token IDs
   * @param {number[]} ids
   * @returns {string}
   */
  decode(ids) {
    const idToToken = Object.fromEntries(
      Object.entries(this.vocab).map(([k, v]) => [v, k])
    );
    return ids.map(id => idToToken[id] || '<unk>').join(' ');
  }

  get vocabSize() {
    return Object.keys(this.vocab).length;
  }
}

/**
 * Tokenizer åŠ è½½å™¨
 * ä» URL æˆ–æœ¬åœ°è·¯å¾„åŠ è½½ tokenizer é…ç½®
 */
class TokenizerLoader {
  constructor() {
    this.cache = new Map();
  }

  /**
   * ä» URL åŠ è½½ tokenizer
   * @param {string} url - tokenizer.json æˆ– tokenizer.txt çš„ URL
   * @param {object} options - åŠ è½½é€‰é¡¹
   * @returns {Promise<ITokenizer>}
   */
  async loadFromUrl(url, options = {}) {
    const { useCache = true, format = 'auto' } = options;

    // æ£€æŸ¥ç¼“å­˜
    if (useCache && this.cache.has(url)) {
      return this.cache.get(url);
    }

    console.log(`ğŸ“¥ Loading tokenizer from: ${url}`);

    try {
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`Failed to load tokenizer: ${response.statusText}`);
      }

      const text = await response.text();
      let tokenizer;

      // æ£€æµ‹æ ¼å¼
      const detectedFormat = format === 'auto' ? this._detectFormat(url, text) : format;

      switch (detectedFormat) {
        case 'json':
          const config = JSON.parse(text);
          tokenizer = new JSONTokenizer(config);
          break;

        case 'wordpiece':
          // WordPiece æ ¼å¼ (vocab.txt)
          const vocab = text.split('\n').filter(l => l.trim());
          tokenizer = this._createWordPieceTokenizer(vocab);
          break;

        default:
          throw new Error(`Unsupported tokenizer format: ${detectedFormat}`);
      }

      if (useCache) {
        this.cache.set(url, tokenizer);
      }

      console.log(`âœ… Tokenizer loaded successfully (vocab size: ${tokenizer.vocabSize})`);

      return tokenizer;
    } catch (error) {
      console.error(`âŒ Failed to load tokenizer:`, error);
      throw error;
    }
  }

  /**
   * ä»é…ç½®å¯¹è±¡åˆ›å»º tokenizer
   * @param {object} config - tokenizer é…ç½®
   * @param {string} type - tokenizer ç±»å‹
   * @returns {ITokenizer}
   */
  createFromConfig(config, type = 'json') {
    switch (type) {
      case 'json':
        return new JSONTokenizer(config);
      default:
        throw new Error(`Unsupported tokenizer type: ${type}`);
    }
  }

  /**
   * æ£€æµ‹ tokenizer æ ¼å¼
   * @private
   */
  _detectFormat(url, content) {
    if (url.endsWith('.json') || content.trim().startsWith('{')) {
      return 'json';
    }
    if (url.endsWith('.txt') || url.includes('vocab')) {
      return 'wordpiece';
    }
    return 'json'; // é»˜è®¤
  }

  /**
   * åˆ›å»º WordPiece tokenizer
   * @private
   */
  _createWordPieceTokenizer(vocab) {
    const vocabMap = {};
    vocab.forEach((token, idx) => {
      vocabMap[token] = idx;
    });

    return new JSONTokenizer({
      model: { vocab: vocabMap }
    });
  }

  /**
   * æ¸…é™¤ç¼“å­˜
   */
  clearCache() {
    this.cache.clear();
  }
}

/**
 * å•ä¾‹å®ä¾‹
 */
const tokenizerLoader = new TokenizerLoader();

/**
 * ä¾¿æ·å‡½æ•°ï¼šä» URL åŠ è½½ tokenizer
 * @param {string} url
 * @param {object} options
 * @returns {Promise<ITokenizer>}
 */
async function loadTokenizer(url, options) {
  return tokenizerLoader.loadFromUrl(url, options);
}

/**
 * ä¾¿æ·å‡½æ•°ï¼šä»é…ç½®åˆ›å»º tokenizer
 * @param {object} config
 * @param {string} type
 * @returns {ITokenizer}
 */
function createTokenizer(config, type = 'json') {
  return tokenizerLoader.createFromConfig(config, type);
}

/**
 * ONNX Web Framework - ç»Ÿä¸€å…¥å£
 * é›†æˆWeb Workerã€æ¨¡å‹ç¼“å­˜ã€é¢„å¤„ç†é’©å­å’Œ Tokenizer æ”¯æŒ
 */

exports.ITokenizer = ITokenizer;
exports.InitializeConfig = InitializeConfig;
exports.JSONTokenizer = JSONTokenizer;
exports.LoadModelRequest = LoadModelRequest;
exports.ModelInfo = ModelInfo;
exports.ONNXWebFramework = ONNXWebFramework;
exports.ONNXWorkerProxy = ONNXWorkerProxy;
exports.RunInferenceRequest = RunInferenceRequest;
exports.TensorData = TensorData;
exports.TokenizerLoader = TokenizerLoader;
exports.WorkerMessageType = WorkerMessageType;
exports.WorkerResponse = WorkerResponse;
exports.createOnnxWorkerProxy = createOnnxWorkerProxy;
exports.createTokenizer = createTokenizer;
exports.default = ONNXWebFramework;
exports.loadTokenizer = loadTokenizer;
exports.tokenizerLoader = tokenizerLoader;
//# sourceMappingURL=index.cjs.map
