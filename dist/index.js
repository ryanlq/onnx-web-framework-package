import * as ort from 'onnxruntime-web';

/**
 * æ¨¡å‹ç¼“å­˜ç®¡ç†å™¨
 * ä½¿ç”¨IndexedDBç¼“å­˜æ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒHTTP Rangeè¯·æ±‚
 */

class ModelCache {
  constructor() {
    this.dbName = 'ONNXModelCache';
    this.dbVersion = 1;
    this.storeName = 'models';
    this.db = null;
  }

  /**
   * åˆå§‹åŒ–ç¼“å­˜æ•°æ®åº“
   */
  async init() {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open(this.dbName, this.dbVersion);

      request.onerror = () => reject(request.error);
      request.onsuccess = () => {
        this.db = request.result;
        resolve();
      };

      request.onupgradeneeded = (event) => {
        const db = event.target.result;
        if (!db.objectStoreNames.contains(this.storeName)) {
          const store = db.createObjectStore(this.storeName, { keyPath: 'url' });
          store.createIndex('timestamp', 'timestamp', { unique: false });
          store.createIndex('etag', 'etag', { unique: false });
        }
      };
    });
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜
   */
  async isCached(url) {
    if (!this.db) await this.init();

    return new Promise((resolve) => {
      const transaction = this.db.transaction([this.storeName], 'readonly');
      const store = transaction.objectStore(this.storeName);
      const request = store.get(url);

      request.onsuccess = () => {
        const cached = request.result;
        if (!cached) {
          resolve(null);
          return;
        }

        // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ24å°æ—¶ï¼‰
        const maxAge = 24 * 60 * 60 * 1000; // 24å°æ—¶
        if (Date.now() - cached.timestamp > maxAge) {
          this.removeFromCache(url);
          resolve(null);
          return;
        }

        resolve(cached);
      };

      request.onerror = () => resolve(null);
    });
  }

  /**
   * è·å–æ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒHTTP Rangeè¯·æ±‚
   */
  async getModel(url) {
    try {
      // é¦–å…ˆæ£€æŸ¥ç¼“å­˜
      const cached = await this.isCached(url);
      if (cached) {
        console.log(`ğŸ“¦ Loading model from cache: ${url}`);
        return cached.data;
      }

      console.log(`â¬‡ï¸  Fetching model from network: ${url}`);

      // æ£€æŸ¥æ˜¯å¦æ”¯æŒRangeè¯·æ±‚
      const headResponse = await fetch(url, { method: 'HEAD' });
      const supportsRange = headResponse.headers.get('Accept-Ranges') === 'bytes';
      const contentLength = headResponse.headers.get('Content-Length');
      const etag = headResponse.headers.get('ETag');

      let modelArray;

      if (supportsRange && contentLength && parseInt(contentLength) > 10 * 1024 * 1024) {
        // å¤§æ–‡ä»¶ä½¿ç”¨åˆ†å—ä¸‹è½½
        modelArray = await this.downloadInChunks(url, contentLength);
      } else {
        // å°æ–‡ä»¶ç›´æ¥ä¸‹è½½
        const response = await fetch(url);
        if (!response.ok) {
          throw new Error(`Failed to fetch model: ${response.statusText}`);
        }
        modelArray = await response.arrayBuffer();
      }

      // ç¼“å­˜æ¨¡å‹
      await this.cacheModel(url, modelArray, etag);

      return modelArray;
    } catch (error) {
      console.error(`Failed to get model ${url}:`, error);
      throw error;
    }
  }

  /**
   * åˆ†å—ä¸‹è½½å¤§æ–‡ä»¶
   */
  async downloadInChunks(url, contentLength) {
    const chunkSize = 1024 * 1024; // 1MB chunks
    const chunks = [];
    let downloaded = 0;

    console.log(`ğŸ“¥ Downloading large model in chunks (${Math.ceil(contentLength / chunkSize)} chunks)`);

    for (let start = 0; start < contentLength; start += chunkSize) {
      const end = Math.min(start + chunkSize - 1, contentLength - 1);
      const range = `bytes=${start}-${end}`;

      const response = await fetch(url, {
        headers: { Range: range }
      });

      if (!response.ok) {
        throw new Error(`Failed to download chunk ${range}: ${response.statusText}`);
      }

      const chunk = await response.arrayBuffer();
      chunks.push(chunk);
      downloaded += chunk.byteLength;

      // æ›´æ–°è¿›åº¦
      const progress = (downloaded / contentLength * 100).toFixed(1);
      console.log(`â³ Download progress: ${progress}% (${downloaded}/${contentLength} bytes)`);
    }

    // åˆå¹¶æ‰€æœ‰å—
    const totalSize = chunks.reduce((sum, chunk) => sum + chunk.byteLength, 0);
    const modelArray = new Uint8Array(totalSize);
    let offset = 0;

    for (const chunk of chunks) {
      modelArray.set(new Uint8Array(chunk), offset);
      offset += chunk.byteLength;
    }

    return modelArray;
  }

  /**
   * ç¼“å­˜æ¨¡å‹æ–‡ä»¶
   */
  async cacheModel(url, data, etag = null) {
    if (!this.db) await this.init();

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);

      const modelRecord = {
        url,
        data,
        timestamp: Date.now(),
        etag,
        size: data.byteLength || data.length
      };

      const request = store.put(modelRecord);
      request.onsuccess = () => resolve();
      request.onerror = () => reject(request.error);
    });
  }

  /**
   * ä»ç¼“å­˜ä¸­ç§»é™¤æ¨¡å‹
   */
  async removeFromCache(url) {
    if (!this.db) await this.init();

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);
      const request = store.delete(url);

      request.onsuccess = () => resolve();
      request.onerror = () => reject(request.error);
    });
  }

  /**
   * æ¸…ç†è¿‡æœŸç¼“å­˜
   */
  async cleanup() {
    if (!this.db) await this.init();

    const maxAge = 24 * 60 * 60 * 1000; // 24å°æ—¶
    const cutoffTime = Date.now() - maxAge;

    return new Promise((resolve, reject) => {
      const transaction = this.db.transaction([this.storeName], 'readwrite');
      const store = transaction.objectStore(this.storeName);
      const index = store.index('timestamp');
      const request = index.openCursor(IDBKeyRange.upperBound(cutoffTime));

      request.onsuccess = (event) => {
        const cursor = event.target.result;
        if (cursor) {
          cursor.delete();
          cursor.continue();
        } else {
          resolve();
        }
      };

      request.onerror = () => reject(request.error);
    });
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
   */
  async getStats() {
    if (!this.db) await this.init();

    return new Promise((resolve) => {
      const transaction = this.db.transaction([this.storeName], 'readonly');
      const store = transaction.objectStore(this.storeName);
      const request = store.getAll();

      request.onsuccess = () => {
        const models = request.result;
        const totalSize = models.reduce((sum, model) => sum + (model.size || 0), 0);
        const stats = {
          count: models.length,
          totalSize,
          models: models.map(model => ({
            url: model.url,
            size: model.size,
            timestamp: model.timestamp,
            age: Date.now() - model.timestamp
          }))
        };
        resolve(stats);
      };

      request.onerror = () => resolve({ count: 0, totalSize: 0, models: [] });
    });
  }
}

/**
 * ONNX Web Framework
 * åŸºäºONNX Runtime Webæ„å»ºï¼Œæ”¯æŒæ¨¡å‹ç¼“å­˜
 */

if (typeof globalThis !== 'undefined') {
  globalThis.ort = ort;
}

class ONNXWebFramework {
  constructor(options = {}) {
    this.options = {
      // ç¼“å­˜é…ç½®
      enableCache: options.enableCache !== false, // é»˜è®¤å¯ç”¨ç¼“å­˜
      cacheMaxAge: options.cacheMaxAge || 24 * 60 * 60 * 1000, // 24å°æ—¶

      // ORTé…ç½®
      executionProviders: options.executionProviders || ['wasm'],
      enableProfiling: options.enableProfiling || false,
      debug: options.debug || false,
      logLevel: options.logLevel || 'warning',
      numThreads: options.numThreads || 0,

      // WASMè·¯å¾„é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤è®©æ‰“åŒ…å·¥å…·è‡ªåŠ¨å¤„ç†ï¼‰
      // åªæœ‰åœ¨éœ€è¦è‡ªå®šä¹‰è·¯å¾„æ—¶æ‰è®¾ç½®ä¸ºå­—ç¬¦ä¸²
      wasmPaths: options.wasmPaths || null,
      ...options
    };

    // ç¼“å­˜å’Œæ¨¡å‹
    this.modelCache = new ModelCache();
    this.models = new Map();
    this.isInitialized = false;
  }

  /**
   * åˆå§‹åŒ–æ¡†æ¶
   */
  async initialize() {
    try {
      console.log('ğŸš€ Initializing ONNX Web Framework...');

      // ä¸è®¾ç½® wasmPathsï¼Œè®©æ‰“åŒ…å·¥å…·è‡ªåŠ¨å¤„ç†
      // å¦‚éœ€è‡ªå®šä¹‰è·¯å¾„ï¼Œå¯é€šè¿‡ options.wasmPaths ä¼ å…¥
      if (this.options.wasmPaths && typeof this.options.wasmPaths === 'string') {
        ort.env.wasm.wasmPaths = this.options.wasmPaths;
        console.log(`ğŸ“ Using custom WASM paths: ${this.options.wasmPaths}`);
      } else {
        console.log('ğŸ“ Using default WASM loader (bundle tool will handle it)');
      }

      // åˆå§‹åŒ–ç¼“å­˜
      if (this.options.enableCache) {
        await this.modelCache.init();
        await this.modelCache.cleanup();
        console.log('âœ… Model cache initialized');
      }

      this.isInitialized = true;
      console.log('âœ… ONNX Web Framework initialized successfully');

      // æ‰“å°ç¼“å­˜ç»Ÿè®¡
      if (this.options.enableCache) {
        const stats = await this.modelCache.getStats();
        console.log(`ğŸ“Š Cache stats: ${stats.count} models, ${(stats.totalSize / 1024 / 1024).toFixed(2)}MB`);
      }

    } catch (error) {
      console.error('âŒ Failed to initialize framework:', error);
      throw error;
    }
  }


  /**
   * åŠ è½½æ¨¡å‹
   */
  async loadModel(name, modelSource, sessionOptions = {}) {
    if (!this.isInitialized) {
      throw new Error('Framework not initialized. Call initialize() first.');
    }

    console.log(`ğŸ“¦ Loading model '${name}'...`);

    try {
      // è·å–æ¨¡å‹æ•°æ®
      let modelArray;
      let modelFormat = 'unknown';

      if (typeof modelSource === 'string') {
        // ä¼˜å…ˆå°è¯•ORTæ ¼å¼
        const ortSource = modelSource.replace(/\.onnx$/, '.ort');

        try {
          modelArray = await this.modelCache.getModel(ortSource);
          modelFormat = 'ort';
          console.log(`âœ… Using ORT format model: ${ortSource}`);
        } catch (ortError) {
          // å›é€€åˆ°ONNXæ ¼å¼
          console.log(`âš ï¸  ORT format not available, using ONNX format`);
          modelArray = await this.modelCache.getModel(modelSource);
          modelFormat = 'onnx';
        }
      } else if (modelSource instanceof Uint8Array || modelSource instanceof ArrayBuffer) {
        modelArray = modelSource;
        modelFormat = 'array';
      } else {
        throw new Error('Invalid model source. Must be URL, Uint8Array, or ArrayBuffer.');
      }

      // åœ¨ä¸»çº¿ç¨‹åŠ è½½æ¨¡å‹
      console.log('âš ï¸  Loading model in main thread (UI may be blocked during inference)');
      const finalOptions = {
        executionProviders: sessionOptions.executionProviders || this.options.executionProviders,
        enableProfiling: sessionOptions.enableProfiling || this.options.enableProfiling,
        ...sessionOptions
      };

      const session = await ort.InferenceSession.create(modelArray, finalOptions);

      // ä¿å­˜æ¨¡å‹ä¿¡æ¯
      this.models.set(name, {
        session,
        modelFormat,
        modelPath: modelSource,
        inputNames: session.inputNames,
        outputNames: session.outputNames
      });

      console.log(`âœ… Model '${name}' loaded successfully (${modelFormat})`);
      return {
        modelName: name,
        loaded: true,
        inputNames: session.inputNames,
        outputNames: session.outputNames
      };

    } catch (error) {
      console.error(`âŒ Failed to load model '${name}':`, error);
      throw error;
    }
  }

  /**
   * æ‰§è¡Œæ¨ç†
   */
  async run(modelName, feeds) {
    if (!this.isInitialized) {
      throw new Error('Framework not initialized. Call initialize() first.');
    }

    const model = this.models.get(modelName);
    if (!model) {
      throw new Error(`Model '${modelName}' not loaded`);
    }

    try {
      // åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œæ¨ç†
      const result = await model.session.run(feeds);
      return result;

    } catch (error) {
      console.error(`âŒ Failed to run inference with model '${modelName}':`, error);
      throw error;
    }
  }

  /**
   * æ‰§è¡Œæ¨ç†ï¼ˆå¸¦é¢„å¤„ç†ï¼‰
   */
  async predict(modelName, rawData, options = {}) {
    throw new Error('predict() not implemented. Please use run() directly with preprocessed tensors.');
  }

  /**
   * é¢„å¤„ç†è¾“å…¥æ•°æ®
   */
  async preprocessInput(model, rawData, preprocessOptions) {
    const processed = {};

    for (const [inputName, inputMeta] of Object.entries(model.inputMetadata)) {
      let inputTensor;

      if (rawData instanceof HTMLImageElement || rawData instanceof HTMLCanvasElement) {
        // å›¾åƒé¢„å¤„ç†
        inputTensor = await this.preprocessImage(rawData, inputMeta, preprocessOptions);
      } else if (Array.isArray(rawData) || rawData instanceof Float32Array) {
        // æ•°ç»„æ•°æ®
        inputTensor = {
          data: rawData,
          shape: preprocessOptions.resize || inputMeta.shape || [1, rawData.length]
        };
      } else if (typeof rawData === 'object' && rawData[inputName]) {
        // å·²ç»æ˜¯å¤„ç†è¿‡çš„å¯¹è±¡
        inputTensor = rawData[inputName];
      } else {
        throw new Error(`Unsupported input data type for '${inputName}'`);
      }

      processed[inputName] = inputTensor;
    }

    return processed;
  }

  /**
   * å›¾åƒé¢„å¤„ç†
   */
  async preprocessImage(image, inputMeta, options) {
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');

    // è°ƒæ•´å°ºå¯¸
    const targetSize = options.resize || [224, 224];
    canvas.width = targetSize[1];
    canvas.height = targetSize[0];

    // ç»˜åˆ¶å›¾åƒ
    ctx.drawImage(image, 0, 0, canvas.width, canvas.height);

    // è·å–åƒç´ æ•°æ®
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const pixels = imageData.data;

    // è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„æ ¼å¼
    const isRGB = options.colorFormat === 'rgb';
    options.normalization || 'zeroToOne';
    const channels = isRGB ? 3 : 4; // RGBæˆ–RGBA
    const data = new Float32Array(canvas.width * canvas.height * channels);

    for (let i = 0, j = 0; i < pixels.length; i += 4, j += channels) {
      // RGBé€šé“
      if (isRGB) {
        data[j] = pixels[i] / 255;     // R
        data[j + 1] = pixels[i + 1] / 255; // G
        data[j + 2] = pixels[i + 2] / 255; // B
      } else {
        data[j] = pixels[i] / 255;     // R
        data[j + 1] = pixels[i + 1] / 255; // G
        data[j + 2] = pixels[i + 2] / 255; // B
        data[j + 3] = pixels[i + 3] / 255; // A
      }
    }

    return {
      data,
      shape: [1, channels, canvas.height, canvas.width] // NCHWæ ¼å¼
    };
  }

  /**
   * è·å–æ¨¡å‹ä¿¡æ¯
   */
  getModelInfo(modelName) {
    return this.models.get(modelName);
  }

  /**
   * åˆ—å‡ºå·²åŠ è½½çš„æ¨¡å‹
   */
  listModels() {
    return Array.from(this.models.keys());
  }

  /**
   * å¸è½½æ¨¡å‹
   */
  async unloadModel(modelName) {
    const model = this.models.get(modelName);
    if (model && model.session) {
      await model.session.release();
    }
    this.models.delete(modelName);
    console.log(`ğŸ—‘ï¸  Model '${modelName}' unloaded`);
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡
   */
  async getCacheStats() {
    if (!this.options.enableCache) {
      return { enabled: false };
    }

    return await this.modelCache.getStats();
  }

  /**
   * æ¸…ç†ç¼“å­˜
   */
  async clearCache() {
    if (!this.options.enableCache) {
      return;
    }

    await this.modelCache.cleanup();
    console.log('ğŸ§¹ Cache cleared');
  }

  /**
   * æ¸…ç†æ‰€æœ‰èµ„æº
   */
  async dispose() {
    // æ¸…ç†Worker
    if (this.workerManager) {
      await this.workerManager.dispose();
      this.workerManager = null;
    }

    // æ¸…ç†æ¨¡å‹
    this.models.clear();

    console.log('ğŸ§¹ ONNX Web Framework disposed');
  }
}

/**
 * ONNX Web Worker ç±»å‹å®šä¹‰
 *
 * å®šä¹‰ Worker å’Œä¸»çº¿ç¨‹ä¹‹é—´çš„æ¶ˆæ¯åè®®
 */

/**
 * Worker æ¶ˆæ¯ç±»å‹æšä¸¾
 */
const WorkerMessageType = {
  INITIALIZE: "initialize",
  LOAD_MODEL: "load_model",
  RUN_INFERENCE: "run_inference",
  DISPOSE: "dispose",
  RESULT: "result",
  ERROR: "error",
};

/**
 * åˆå§‹åŒ–é…ç½®
 */
class InitializeConfig {
  constructor(options = {}) {
    /**
     * WASM æ–‡ä»¶è·¯å¾„é…ç½®
     * @type {string | Record<string, string>}
     */
    this.wasmPaths = options.wasmPaths || null;

    /**
     * çº¿ç¨‹æ•°é‡ï¼ˆ0 = ä½¿ç”¨é»˜è®¤å€¼ï¼‰
     * @type {number}
     */
    this.numThreads = options.numThreads || 0;

    /**
     * æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æ
     * @type {boolean}
     */
    this.enableProfiling = options.enableProfiling || false;

    /**
     * æ‰§è¡Œæä¾›è€…åˆ—è¡¨
     * @type {string[]}
     */
    this.executionProviders = options.executionProviders || ["wasm"];
  }
}

/**
 * å¼ é‡æ•°æ®
 */
class TensorData {
  constructor(data, dims, type = "float32") {
    /**
     * å¼ é‡æ•°æ®ï¼ˆFloat32Array | Int32Array | Uint8Array | BigInt64Arrayï¼‰
     */
    this.data = data;

    /**
     * å¼ é‡ç»´åº¦
     * @type {number[]}
     */
    this.dims = dims;

    /**
     * æ•°æ®ç±»å‹
     * @type {'float32' | 'int32' | 'uint8' | 'int64'}
     */
    this.type = type;
  }
}

/**
 * åŠ è½½æ¨¡å‹è¯·æ±‚
 */
class LoadModelRequest {
  constructor(id, modelName, modelBuffer, sessionOptions = {}) {
    /**
     * è¯·æ±‚ ID
     * @type {string}
     */
    this.id = id;

    /**
     * è¯·æ±‚ç±»å‹
     * @type {string}
     */
    this.type = WorkerMessageType.LOAD_MODEL;

    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * æ¨¡å‹æ•°æ®ï¼ˆArrayBufferï¼‰
     * @type {ArrayBuffer}
     */
    this.modelBuffer = modelBuffer;

    /**
     * Session é…ç½®é€‰é¡¹
     * @type {Object}
     */
    this.sessionOptions = sessionOptions;
  }
}

/**
 * æ¨ç†è¯·æ±‚
 */
class RunInferenceRequest {
  constructor(id, modelName, inputs) {
    /**
     * è¯·æ±‚ ID
     * @type {string}
     */
    this.id = id;

    /**
     * è¯·æ±‚ç±»å‹
     * @type {string}
     */
    this.type = WorkerMessageType.RUN_INFERENCE;

    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * è¾“å…¥å¼ é‡å­—å…¸
     * @type {Record<string, TensorData>}
     */
    this.inputs = inputs;
  }
}

/**
 * Worker å“åº”
 */
class WorkerResponse {
  constructor(id, type, data = null, error = null) {
    /**
     * å“åº” IDï¼ˆå¯¹åº”è¯·æ±‚ IDï¼‰
     * @type {string}
     */
    this.id = id;

    /**
     * å“åº”ç±»å‹
     * @type {string}
     */
    this.type = type;

    /**
     * å“åº”æ•°æ®
     * @type {any}
     */
    this.data = data;

    /**
     * é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
     * @type {string | null}
     */
    this.error = error;
  }
}

/**
 * æ¨¡å‹ä¿¡æ¯
 */
class ModelInfo {
  constructor(modelName, inputNames, outputNames) {
    /**
     * æ¨¡å‹åç§°
     * @type {string}
     */
    this.modelName = modelName;

    /**
     * è¾“å…¥åç§°åˆ—è¡¨
     * @type {string[]}
     */
    this.inputNames = inputNames;

    /**
     * è¾“å‡ºåç§°åˆ—è¡¨
     * @type {string[]}
     */
    this.outputNames = outputNames;
  }
}

/**
 * ONNX Worker Proxy
 *
 * å°è£… Worker é€šä¿¡ï¼Œæä¾› Promise API
 * ä½¿ç”¨ Proxy æ¨¡å¼è®©è°ƒç”¨ Worker å°±åƒè°ƒç”¨æœ¬åœ°å‡½æ•°ä¸€æ ·ç®€å•
 *
 * ä½¿ç”¨ç¤ºä¾‹:
 * ```javascript
 * import workerUrl from 'onnx-web-framework/worker?worker&url'
 * import { createOnnxWorkerProxy } from 'onnx-web-framework'
 *
 * const worker = new Worker(workerUrl, { type: 'module' })
 * const proxy = createOnnxWorkerProxy(worker)
 *
 * await proxy.initialize({ wasmPaths: '/wasm/' })
 * await proxy.loadModel('model', modelBuffer)
 * const result = await proxy.run('model', inputs)
 * ```
 */


/**
 * ONNX Worker ä»£ç†ç±»
 *
 * å°è£… Worker é€šä¿¡ï¼Œæä¾› Promise API
 */
class ONNXWorkerProxy {
  /**
   * æ„é€ å‡½æ•°
   *
   * @param {Worker} worker - Web Worker å®ä¾‹
   */
  constructor(worker) {
    /**
     * Web Worker å®ä¾‹
     * @type {Worker}
     * @private
     */
    this.worker = worker;

    /**
     * è¯·æ±‚ ID è®¡æ•°å™¨
     * @type {number}
     * @private
     */
    this.requestId = 0;

    /**
     * å¾…å¤„ç†çš„è¯·æ±‚ Map
     * @type {Map<number, {resolve: Function, reject: Function, timeout: number}>}
     * @private
     */
    this.pendingRequests = new Map();

    /**
     * é»˜è®¤è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
     * @type {number}
     * @private
     */
    this.defaultTimeout = 60000; // 60ç§’

    /**
     * æ˜¯å¦å·²é‡Šæ”¾
     * @type {boolean}
     * @private
     */
    this.isDisposed = false;

    // ç»‘å®šæ¶ˆæ¯å¤„ç†å™¨
    this.worker.onmessage = this._handleMessage.bind(this);

    // ç»‘å®šé”™è¯¯å¤„ç†å™¨
    this.worker.onerror = this._handleError.bind(this);
  }

  /**
   * å¤„ç† Worker æ¶ˆæ¯
   * @private
   *
   * @param {MessageEvent<WorkerResponse>} e - æ¶ˆæ¯äº‹ä»¶
   */
  _handleMessage(e) {
    if (this.isDisposed) return;

    const res = e.data;
    const pending = this.pendingRequests.get(res.id);

    if (!pending) {
      console.warn(`[WorkerProxy] æ²¡æœ‰æ‰¾åˆ° ID ä¸º ${res.id} çš„å¾…å¤„ç†è¯·æ±‚`);
      return;
    }

    // æ¸…ç†è¶…æ—¶å®šæ—¶å™¨
    if (pending.timeout) {
      clearTimeout(pending.timeout);
    }

    // ä»å¾…å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
    this.pendingRequests.delete(res.id);

    // å¤„ç†å“åº”
    if (res.type === WorkerMessageType.ERROR || res.error) {
      pending.reject(new Error(res.error || 'Unknown error'));
    } else {
      pending.resolve(res.data);
    }
  }

  /**
   * å¤„ç† Worker é”™è¯¯
   * @private
   *
   * @param {ErrorEvent} e - é”™è¯¯äº‹ä»¶
   */
  _handleError(e) {
    console.error('[WorkerProxy] Worker é”™è¯¯:', e.message, e);

    // æ‹’ç»æ‰€æœ‰å¾…å¤„ç†çš„è¯·æ±‚
    for (const [id, pending] of this.pendingRequests.entries()) {
      if (pending.timeout) {
        clearTimeout(pending.timeout);
      }
      pending.reject(new Error(`Worker error: ${e.message}`));
    }

    this.pendingRequests.clear();
  }

  /**
   * å‘é€è¯·æ±‚åˆ° Worker
   * @private
   *
   * @param {string} type - è¯·æ±‚ç±»å‹
   * @param {Object} data - è¯·æ±‚æ•°æ®
   * @param {number} timeout - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   * @returns {Promise<any>}
   */
  async _request(type, data = {}, timeout = null) {
    if (this.isDisposed) {
      throw new Error('WorkerProxy has been disposed');
    }

    const id = ++this.requestId;
    const reqTimeout = timeout || this.defaultTimeout;

    return new Promise((resolve, reject) => {
      // åˆ›å»ºè¶…æ—¶å®šæ—¶å™¨
      const timeoutId = setTimeout(() => {
        this.pendingRequests.delete(id);
        reject(new Error(`Request timeout: ${type} (${reqTimeout}ms)`));
      }, reqTimeout);

      // ä¿å­˜å¾…å¤„ç†è¯·æ±‚
      this.pendingRequests.set(id, {
        resolve,
        reject,
        timeout: timeoutId
      });

      // å‘é€æ¶ˆæ¯åˆ° Worker
      try {
        this.worker.postMessage({
          id,
          type,
          ...data
        });
      } catch (error) {
        // å‘é€å¤±è´¥ï¼Œç«‹å³æ¸…ç†
        clearTimeout(timeoutId);
        this.pendingRequests.delete(id);
        reject(error);
      }
    });
  }

  /**
   * åˆå§‹åŒ– Worker
   *
   * @param {Partial<InitializeConfig>} config - åˆå§‹åŒ–é…ç½®
   * @returns {Promise<void>}
   *
   * @example
   * await proxy.initialize({
   *   wasmPaths: 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/',
   *   numThreads: 4
   * })
   */
  async initialize(config = {}) {
    const initConfig = new InitializeConfig(config);
    await this._request(WorkerMessageType.INITIALIZE, { config: initConfig });
    console.log('[WorkerProxy] âœ… Worker åˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * åŠ è½½æ¨¡å‹
   *
   * @param {string} modelName - æ¨¡å‹åç§°ï¼ˆç”¨äºåç»­å¼•ç”¨ï¼‰
   * @param {ArrayBuffer} modelBuffer - æ¨¡å‹æ•°æ®ï¼ˆArrayBufferï¼‰
   * @param {Object} sessionOptions - Session é…ç½®é€‰é¡¹
   * @returns {Promise<{modelName: string, inputNames: string[], outputNames: string[]}>}
   *
   * @example
   * const modelResponse = await fetch('/models/model.onnx')
   * const modelBuffer = await modelResponse.arrayBuffer()
   * const info = await proxy.loadModel('my-model', modelBuffer)
   * console.log('è¾“å…¥:', info.inputNames)
   * console.log('è¾“å‡º:', info.outputNames)
   */
  async loadModel(modelName, modelBuffer, sessionOptions = {}) {
    if (!modelName) {
      throw new Error('modelName is required');
    }
    if (!modelBuffer) {
      throw new Error('modelBuffer is required');
    }

    const result = await this._request(WorkerMessageType.LOAD_MODEL, {
      modelName,
      modelBuffer,
      sessionOptions
    });

    console.log(`[WorkerProxy] âœ… æ¨¡å‹ '${modelName}' åŠ è½½æˆåŠŸ`);
    return result;
  }

  /**
   * è¿è¡Œæ¨ç†
   *
   * @param {string} modelName - æ¨¡å‹åç§°
   * @param {Record<string, TensorData>} inputs - è¾“å…¥å¼ é‡å­—å…¸
   * @returns {Promise<Record<string, TensorData>>} è¾“å‡ºå¼ é‡å­—å…¸
   *
   * @example
   * const result = await proxy.run('my-model', {
   *   input: {
   *     data: new Float32Array([1, 2, 3]),
   *     dims: [1, 3],
   *     type: 'float32'
   *   }
   * })
   */
  async run(modelName, inputs) {
    if (!modelName) {
      throw new Error('modelName is required');
    }
    if (!inputs || Object.keys(inputs).length === 0) {
      throw new Error('inputs is required');
    }

    return await this._request(WorkerMessageType.RUN_INFERENCE, {
      modelName,
      inputs
    });
  }

  /**
   * é‡Šæ”¾ Worker èµ„æº
   *
   * @returns {Promise<void>}
   *
   * @example
   * await proxy.dispose()
   */
  async dispose() {
    if (this.isDisposed) {
      console.warn('[WorkerProxy] å·²ç»é‡Šæ”¾è¿‡äº†');
      return;
    }

    console.log('[WorkerProxy] æ­£åœ¨é‡Šæ”¾...');

    // å‘é€é‡Šæ”¾æ¶ˆæ¯
    try {
      await this._request(WorkerMessageType.DISPOSE, {}, 5000);
    } catch (error) {
      console.warn('[WorkerProxy] é‡Šæ”¾æ¶ˆæ¯å‘é€å¤±è´¥:', error);
    }

    // æ¸…ç†æ‰€æœ‰å¾…å¤„ç†è¯·æ±‚
    for (const [id, pending] of this.pendingRequests.entries()) {
      if (pending.timeout) {
        clearTimeout(pending.timeout);
      }
      pending.reject(new Error('Worker disposed'));
    }

    this.pendingRequests.clear();

    // ç»ˆæ­¢ Worker
    this.worker.terminate();

    // æ ‡è®°ä¸ºå·²é‡Šæ”¾
    this.isDisposed = true;

    console.log('[WorkerProxy] âœ… é‡Šæ”¾å®Œæˆ');
  }

  /**
   * æ£€æŸ¥ Worker æ˜¯å¦å·²é‡Šæ”¾
   *
   * @returns {boolean}
   */
  get disposed() {
    return this.isDisposed;
  }
}

/**
 * åˆ›å»º ONNX Worker ä»£ç†
 *
 * è¿™æ˜¯æ¨èçš„åˆ›å»º Worker Proxy çš„æ–¹å¼
 *
 * @param {Worker} worker - Web Worker å®ä¾‹
 * @returns {ONNXWorkerProxy} Worker ä»£ç†å®ä¾‹
 *
 * @example
 * // Vite é¡¹ç›®
 * import workerUrl from 'onnx-web-framework/worker?worker&url'
 * import { createOnnxWorkerProxy } from 'onnx-web-framework'
 *
 * const worker = new Worker(workerUrl, { type: 'module' })
 * const proxy = createOnnxWorkerProxy(worker)
 *
 * await proxy.initialize()
 * await proxy.loadModel('model', modelBuffer)
 * const result = await proxy.run('model', inputs)
 */
function createOnnxWorkerProxy(worker) {
  return new ONNXWorkerProxy(worker);
}

/**
 * ONNX Web Framework - ç»Ÿä¸€å…¥å£
 * é›†æˆWeb Workerã€æ¨¡å‹ç¼“å­˜å’Œæ˜¾å¼å¼ é‡ç®¡ç†
 */

export { InitializeConfig, LoadModelRequest, ModelInfo, ONNXWebFramework, ONNXWorkerProxy, RunInferenceRequest, TensorData, WorkerMessageType, WorkerResponse, createOnnxWorkerProxy, ONNXWebFramework as default };
//# sourceMappingURL=index.js.map
